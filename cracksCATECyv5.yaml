path: ../datasets/cracksCATECyv5  # dataset root dir
train: images/train  # train images (relative to 'path') 128 images
val: images/val  # val images (relative to 'path') 128 images
test:

# Classes
nc: 1  # number of classes
names: ['crack']  # class names

# Download script/URL (optional)
download: |
  import os
  import gdown
  from pathlib import Path
  from zipfile import ZipFile, is_zipfile
  from tqdm import tqdm

  dataset_dir = str(Path(yaml['path']))

  # Parameters of the gdown.download() method
  gdrive_file_id = '1spdG7sAZ4oVWm6kWk0_PjRw_72Q4w4_L'
  download_url = f"https://drive.google.com/uc?id={gdrive_file_id}"
  dowloaded_file = os.path.join(dataset_dir, 'cracksCATECyv5.zip')

  # Create dataset directory in case it does not exists
  if not os.path.exists(dataset_dir):
      os.makedirs(dataset_dir)
  else:
      print(f"Directory '{dataset_dir}' exists, skipping creation.")

  # Download zip file
  if (not os.path.exists(dowloaded_file)) and (not os.path.isfile(dowloaded_file)):
      gdown.download(download_url, dowloaded_file, False)
  else:
      print(f"File '{dataset_dir}' exists, skipping download.")

  # Extract zip if it exists
  if os.path.exists(dowloaded_file):
      if is_zipfile(dowloaded_file):
          print(f"Extracting: '{dowloaded_file}'")
          with ZipFile(dowloaded_file,"r") as zip_ref:
            for file in tqdm(iterable=zip_ref.namelist(), total=len(zip_ref.namelist())):
                zip_ref.extract(member=file, path=dataset_dir)
      else:
          print("Not valid zip file")
  else:
      print(f"Extraction failed. '{dowloaded_file}' does not exist")


  for dirpath, dirnames, filenames in os.walk(dataset_dir):
      directory_level = dirpath.replace(dataset_dir, "")
      directory_level = directory_level.count(os.sep)
      indent = " " * 4
      print("{}{}/".format(indent*directory_level, os.path.basename(dirpath)))
